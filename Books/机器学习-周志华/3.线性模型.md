# 线性模型

## 简介

<img src="./images/image-20240716163657808.png" alt="image-20240716163657808" style="zoom:67%;" />

线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数：
$$
f(x)=w_1x_1+w_2x_2+\cdots+w_dx_d+b
$$

向量形式：

$$
f(x)=w^Tx+b
$$

线性模型简单、基本、可理解性好。

**线性回归（linear regression）**

$$
f(x_i)=wxi+b
$$

使得：

$$
f(x_i)\approx y_i
$$

数据预处理——离散变量转换为数值：

- 有序变量直接转换为数值
- 无序变量转换为 one-hot

线性回归处理方案——令均方误差最小化：

$$
\begin{aligned}
(w^*,b^*)&={\text{arg min}\atop (w,b)} \sum_{i=1}^m(f(x_i)-y_i)^2\\
&={\text{arg min} \atop (w,b)} \sum_{i=1}^m (y_i-wx_i-b)^2
\end{aligned}
$$

对 $E_{(w,b)}=\sum_{i=1}^m (y_i-wx_i-b)^2$ 进行最小二乘参数估计。

> `;` 对应列向量，`,` 对应行向量。

## 最小二乘解

最小二乘估计就是对 $E_{(w,b)}=\sum_{i=1}^m (y_i-wx_i-b)^2$  求偏导，让导数为 0.

分别对 $w$ 和 $b$ 求导：
$$
\frac{\partial E(w,b)}{\partial w}=2(w\sum_{i=1}^m x_i^2-\sum_{i=1}^m (y_i-b)x_i)
$$

$$
\frac{\partial E(w.b)}{\partial b}=2(mb-\sum_{i=1}^m (y_i-wx_i))
$$

令导数为 0，得到闭式（closed-form）解：

$$
w=\frac{\sum_{i=1}^m y_i(x_i-\overline{x})}{\sum_{i=1}^m x_i^2-\frac{1}{m}(\sum_{i=1}^m x_i)^2}
$$

$$
b=\frac{1}{m}\sum_{i=1}^m (y_i-wx_i)
$$

## 多元线性回归

多元（multi-variate）就是多变量。

$$
f(\bold{x}_i)=\bold{w}^T\bold{x}_i+b
$$

使得：

$$
f(x_i)\approx y_i
$$

其中，$\bold{x}_i=(x_{i1};x_{i2};\cdots;x_{id};)$。


