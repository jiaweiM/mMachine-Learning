# 卷积神经网络

- [卷积神经网络](#卷积神经网络)
  - [简介](#简介)
  - [卷积](#卷积)
    - [定义](#定义)
    - [一维卷积](#一维卷积)
  - [参考](#参考)

2021-06-04, 09:16
***

## 简介

卷积神经网络（Convolutional Neural Network, CNN或 ConvNet）是一种具有**局部连接**、**权重共享**等特性的深层前馈神经网络。

卷积神经网络最早主要用来处理图像信息。在用全连接前馈神经网络处理图像时，会存在以下两个问题：

1. 参数太多

如果输入图像大小为 100x100x3 （即高 100，宽 100，RGB 3 通道），在全连接前馈网络中，第一个隐藏层每个神经元到输入层有 100x100x3=30 000 个互相独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量的增多，参数的规模也会急剧增加。这会导致整个神经网络的训练效率非常低，也很容易出现过拟合。

2. 局部不变性特征

自然图像中的物体都具有局部不变性特征，比如尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部变性特征，一般需要进行**数据增强**来提高性能。

卷积神经网络是受生物学上感受野的启发而提出的。**感受野**（Receptive Field）机制主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层汇总的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有视觉皮层中的神经元都会接受这些信号。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元。

目前的卷积神经网络一般是由卷积层、汇聚层和全连接层交叉堆叠而成的前馈神经网络，全连接层一般在卷积网络的最顶层。卷积神经网络有三个结构上的特性：**局部连接**、**权重共享**以及**汇聚**。这些特性使得CNN具有一定程度的平移、缩放和旋转不变性。和前馈神经网络相比，CNN的参数更少。

CNN 主要用在图像和视频分析中，如图像分类、人脸识别、物体识别和图像分隔等，其准确率一般远远超过其他的神经网络模型。近年来，CNN 也广泛地应用到自然语言处理、推荐系统等领域。

## 卷积

### 定义

卷积（Convolution），也叫褶积，是分析数学中的一种运算。在信号处理和图像处理中，经常使用一维或二维卷积。

### 一维卷积

一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻 t 产生一个信号 $x_t$，其信息的衰减率为 $w_k$，即在 $k-1$个时间步长后，信息为原来的 $w_k$倍。假设 $w_1=1, w_2=1/2,w_3=1/4$，那么在时刻 t 收到的信号 $y_t$ 为当前时刻产生的信息和以上时刻延迟信息的叠加，

$$
\begin{aligned}
y_t &= 1\times x_t +1/2\times x_{t-1}+1/4\times x_{t-2}\\
&=w_1\times x_t+w_2\times x_{t-1}+w_3\times x_{t-2}\\
&=\sum _{k=1}^3 w_kx_{t-k+1}
\end{aligned}
$$

我们把 $w_1, w_2,...$称为滤波器（Filter）或卷积核（Convolution Kernel）。假设滤波器长度为 K，它和一个信号序列 $x_1, x_2,...$的卷积为：

$$y_t=\sum_{k=1}^K w_kx_{t-k+1}$$

信号序列 x 和滤波器 w 的卷积定义为：

$$y=w*x$$

其中 * 表示卷积运算。一般情况下滤波器的长度 K 远小于信号序列 x 的长度。

我们可以设计不同的滤波器来提取信号序列的不同特征。比如，当令滤波器 $w=[1/K,...1/K]$时，卷积相当于信号序列的简单移动平均（窗口大小为K）；

## 参考

- 神经网络与深度学习，邱锡鹏
