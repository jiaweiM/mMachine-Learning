{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 使用 3 层网络定义 Sequential 模型\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation='relu', name='layer1'),\n",
    "        layers.Dense(3, activation='relu', name='layer2'),\n",
    "        layers.Dense(4, name='layer3')\n",
    "    ]\n",
    ")\n",
    "# 对测试样本调用模型\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layer1 = layers.Dense(2, activation='relu', name='layer1')\n",
    "layer2 = layers.Dense(3, activation='relu', name='layer2')\n",
    "layer3 = layers.Dense(4, name='layer3')\n",
    "\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu'),\n",
    "    layers.Dense(3, activation='relu'),\n",
    "    layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x12a2cbaf880>,\n",
       " <keras.layers.core.dense.Dense at 0x12a2cbaf310>,\n",
       " <keras.layers.core.dense.Dense at 0x12a0554e8b0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_3/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[-0.40250832,  0.3771119 , -0.8667558 ],\n",
       "        [ 0.12981272, -0.8541893 ,  0.8584156 ],\n",
       "        [ 0.26037717,  0.5907799 , -0.44195348],\n",
       "        [ 0.6888095 , -0.70434684,  0.4315971 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu'),\n",
    "    layers.Dense(3, activation='relu'),\n",
    "    layers.Dense(4)\n",
    "])  # 此时没有 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_2 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\n",
      "File \u001B[1;32mD:\\conda3\\envs\\d2l\\lib\\site-packages\\keras\\engine\\training.py:2542\u001B[0m, in \u001B[0;36mModel.weights\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2532\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   2533\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mweights\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   2534\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns the list of all layer variables/weights.\u001B[39;00m\n\u001B[0;32m   2535\u001B[0m \n\u001B[0;32m   2536\u001B[0m \u001B[38;5;124;03m  Note: This will not track the weights of nested `tf.Modules` that are not\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2540\u001B[0m \u001B[38;5;124;03m    A list of variables.\u001B[39;00m\n\u001B[0;32m   2541\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2542\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dedup_weights(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_undeduplicated_weights\u001B[49m)\n",
      "File \u001B[1;32mD:\\conda3\\envs\\d2l\\lib\\site-packages\\keras\\engine\\training.py:2547\u001B[0m, in \u001B[0;36mModel._undeduplicated_weights\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2544\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   2545\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_undeduplicated_weights\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   2546\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2547\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_assert_weights_created\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2548\u001B[0m   weights \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   2549\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_tracked_trackables:\n",
      "File \u001B[1;32mD:\\conda3\\envs\\d2l\\lib\\site-packages\\keras\\engine\\sequential.py:471\u001B[0m, in \u001B[0;36mSequential._assert_weights_created\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    468\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;66;03m# When the graph has not been initialized, use the Model's implementation to\u001B[39;00m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;66;03m# to check if the weights has been created.\u001B[39;00m\n\u001B[1;32m--> 471\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFunctional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_assert_weights_created\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda3\\envs\\d2l\\lib\\site-packages\\keras\\engine\\training.py:2736\u001B[0m, in \u001B[0;36mModel._assert_weights_created\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2728\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   2730\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbuild\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   2731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;241m!=\u001B[39m Model \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   2732\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt):\n\u001B[0;32m   2733\u001B[0m   \u001B[38;5;66;03m# For any model that has customized build() method but hasn't\u001B[39;00m\n\u001B[0;32m   2734\u001B[0m   \u001B[38;5;66;03m# been invoked yet, this will cover both sequential and subclass model.\u001B[39;00m\n\u001B[0;32m   2735\u001B[0m   \u001B[38;5;66;03m# Also make sure to exclude Model class itself which has build() defined.\u001B[39;00m\n\u001B[1;32m-> 2736\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeights for model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m have not yet been \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2737\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreated. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2738\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeights are created when the Model is first called on \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2739\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minputs or `build()` is called with an `input_shape`.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Weights for model sequential_2 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights  # 会抛出错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda3\\envs\\d2l\\lib\\site-packages\\keras\\engine\\training.py:2579\u001B[0m, in \u001B[0;36mModel.summary\u001B[1;34m(self, line_length, positions, print_fn, expand_nested)\u001B[0m\n\u001B[0;32m   2559\u001B[0m \u001B[38;5;124;03m\"\"\"Prints a string summary of the network.\u001B[39;00m\n\u001B[0;32m   2560\u001B[0m \n\u001B[0;32m   2561\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2576\u001B[0m \u001B[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001B[39;00m\n\u001B[0;32m   2577\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2578\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m-> 2579\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2580\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis model has not yet been built. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2581\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBuild the model first by calling `build()` or by calling \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2582\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe model on a batch of data.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   2583\u001B[0m layer_utils\u001B[38;5;241m.\u001B[39mprint_summary(\n\u001B[0;32m   2584\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2585\u001B[0m     line_length\u001B[38;5;241m=\u001B[39mline_length,\n\u001B[0;32m   2586\u001B[0m     positions\u001B[38;5;241m=\u001B[39mpositions,\n\u001B[0;32m   2587\u001B[0m     print_fn\u001B[38;5;241m=\u001B[39mprint_fn,\n\u001B[0;32m   2588\u001B[0m     expand_nested\u001B[38;5;241m=\u001B[39mexpand_nested)\n",
      "\u001B[1;31mValueError\u001B[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()  # 也会抛出错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (1, 2)                    10        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (1, 3)                    9         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, 4)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x12ad7175730>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(4,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB 图片\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation='relu'))\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 32)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,002\n",
      "Trainable params: 49,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers]\n",
    ")\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n array([[[[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]],\n \n         [[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]],\n \n         [[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]],\n \n         ...,\n \n         [[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]],\n \n         [[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]],\n \n         [[0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          ...,\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ],\n          [0.1191241 , 0.07604697, 0.        , ..., 0.19091254,\n           0.33169365, 0.        ]]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n array([[[[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]],\n \n         [[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]],\n \n         [[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]],\n \n         ...,\n \n         [[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]],\n \n         [[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]],\n \n         [[0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          ...,\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856],\n          [0.        , 0.        , 0.        , ..., 0.3269807 ,\n           0.08486766, 0.03834856]]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n array([[[[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]],\n \n         [[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]],\n \n         [[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]],\n \n         ...,\n \n         [[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]],\n \n         [[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]],\n \n         [[0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          ...,\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ],\n          [0.0977094 , 0.17091651, 0.        , ..., 0.        ,\n           0.14746605, 0.        ]]]], dtype=float32)>]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\narray([[[[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]],\n\n        [[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]],\n\n        [[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]],\n\n        ...,\n\n        [[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]],\n\n        [[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]],\n\n        [[0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         ...,\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ],\n         [0.        , 0.39142978, 0.        , ..., 0.42282772,\n          0.06077018, 0.0272972 ]]]], dtype=float32)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation='relu'),\n",
    "        layers.Conv2D(32, 3, activation='relu', name='my_intermediate_layer'),\n",
    "        layers.Conv2D(32, 3, activation='relu')\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name='my_intermediate_layer').output\n",
    ")\n",
    "# call feature extractor on test input\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}