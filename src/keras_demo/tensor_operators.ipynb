{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 张量运算\r\n",
    "\r\n",
    "深度神经网络学到的所有变换都可以简化为数值数据张量上的一些**张量运算**（tensor operation）。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 逐元素运算\r\n",
    "\r\n",
    "relu 运算和加法都是逐元素（element-wise）运算，即该运算独立地应用于张量中的每个元素，这些运算非常适合大规模并行实现（向量化实现） 。如果你想对逐元素运算编写简单的 Python 实现，那么可以用for循环。\r\n",
    "\r\n",
    "下面是对逐元素 relu 运算的简单实现"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def native_relu(x):\r\n",
    "    assert len(x.shape) == 2 # x 是一个 Numpy 2D 张量\r\n",
    "    x = x.copy() # 避免覆盖输入张量\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] = max(x[i, j], 0)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "对于加法采用同样的实现方法。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def native_add(x, y):\r\n",
    "    assert len(x.shape) == 2 # x 和 y 是 Numpy 的 2D 张量\r\n",
    "    assert x.shape == y.shape\r\n",
    "\r\n",
    "    x = x.copy()\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] += y[i, j]\r\n",
    "    \r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用同样的方法可以实现逐元素的乘法、减法等。\r\n",
    "\r\n",
    "在实践中处理 Numpy 数组时，这些运算都是优化好的 Numpy 内置函数，这些函数将大量运算交给安装好的基础线性代数子程序（BLAS，basic linear algebra subprograms）实现。BLAS是低层次的、高度并行的、高效的张量操作程序，通常用 Fortran 或 C 语言来实现。\r\n",
    "\r\n",
    "因此在Numpy 中可以直接进行下列逐元素运算，速度非常快。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 广播\r\n",
    "\r\n",
    "当两个 shape 不同的张量之间进行计算，在没有歧义的情况下，较小的张量会被广播（broadcast），以匹配较大的张量的形状。广播包含两步：\r\n",
    "\r\n",
    "1. 向较小的张量添加轴（叫做广播轴），使其 ndim 与较大的张量相同。\r\n",
    "2. 将较小的张量沿着新轴重复，使其形状与较大的张量相同。\r\n",
    "\r\n",
    "例如，假设 X 的形状是 (32, 10)，y 的形状是 (10,)。首先，我们给 y 添加空的第一个轴，这样 y 的形状就变为（1，10）。然后，将 y 沿着新轴重复 32 次，这样得到的张量 Y 的形状为 (32, 10)，并且 `Y[i, :] == y for i in range(0, 32)`。现在 X 和 Y 形状相同，可以相加。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "x = np.random.random((64, 3, 32, 10))\r\n",
    "y = np.random.random((32, 10))\r\n",
    "\r\n",
    "z = np.maximum(x, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(z.shape) # z 的形状和 x 一致"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64, 3, 32, 10)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量点积\r\n",
    "\r\n",
    "点积运算，也叫张量积（tensor product），是最常见也最有用的张量运算。与逐元素运算不同，它将输入张量的元素合并在一起。\r\n",
    "\r\n",
    "在 Numpy, Keras, Theano 和 TensorFlow 中，都用 `*` 实现逐元素乘积。TensorFlow 中的点积使用了不同的语法，但是在 Numpy 和 keras 中，都是用标准的 dot 运算符来实现点积。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "z = np.dot(x, y)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "shapes (64,3,32,10) and (32,10) not aligned: 10 (dim 3) != 32 (dim 0)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b55ef2133d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (64,3,32,10) and (32,10) not aligned: 10 (dim 3) != 32 (dim 0)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "e404b59586357c814bc0d3940e75d6763c00a48753b225b81f7716971b8e1741"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}