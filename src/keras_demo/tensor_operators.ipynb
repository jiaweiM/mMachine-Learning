{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 张量运算\r\n",
    "\r\n",
    "深度神经网络学到的所有变换都可以简化为数值数据张量上的一些张量运算（tensor operation）。\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 逐元素运算\r\n",
    "\r\n",
    "独立地应用于张量中的每个元素的运算。下面是对逐元素 relu 运算的简单实现"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def native_relu(x):\r\n",
    "    assert len(x.shape) == 2 # x 是一个 Numpy 的 2D 张量\r\n",
    "    x = x.copy() # 避免覆盖输入张量\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] = max(x[i, j], 0)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def native_add(x, y):\r\n",
    "    assert len(x.shape) == 2 # x 和 y 是 Numpy 的 2D 张量\r\n",
    "    assert x.shape == y.shape\r\n",
    "\r\n",
    "    x = x.copy()\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] += y[i, j]\r\n",
    "    \r\n",
    "    return x\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 广播\r\n",
    "\r\n",
    "广播包含两步：\r\n",
    "\r\n",
    "1. 向较小的张量添加轴（叫做广播轴），使其 ndim 与较大的张量相同。\r\n",
    "2. 将较小的张量沿着新轴重复，使其形状与较大的张量相同。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}