{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST 手写数字识别"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先，导入 keras 包，导入 mnist 数据集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from tensorflow.keras.datasets import mnist\r\n",
    "\r\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "train_images 和 train_labels 组成了训练集，模型将从这些数据中进行学习。然后再测试集 test_images 和 test_labels 上对模型进行测试。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "图像被编码为 Numpy 数组，而标签是数字数组，取值范围为 0~9。图像和标签一一对应。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_images.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(train_labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_images.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面是测试数据："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "len(test_labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_images.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来的工作流程：\r\n",
    "\r\n",
    "- 将训练数据（train_images 和 train_labels）输入神经网络；\r\n",
    "- 网络学习将图像和标签关联在一起；\r\n",
    "- 使用网络对 test_images 生成预测，验证这些预测与 test_labels 中的标签是否匹配。\r\n",
    "\r\n",
    "下面构建网络"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "network = models.Sequential()\r\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\r\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "神经网络的核心是层（layer），它是一种数据处理模块。具体来说，层从输入数据种提取表示——我们期望这种表示有助于解决手头的问题。大多数深度学习都是将简单的层链接起来，从而实现渐进式的**数据蒸馏**（data distillation）。深度学习模型就像是一个数据处理的筛子，包含一系列越来越精细的数据过滤器。\r\n",
    "\r\n",
    "上面的网络包含 2 个 Dense 层，它们是密集连接（也叫全连接）的神经层。第二层是一个 10 路 softmax 层，它将返回一个由 10 个概率值（总和为 1）组成的数组。每个概率值表示当前数字图像属于 10 个数字类别中某一个的概率。\r\n",
    "\r\n",
    "要向训练网络，还需要进行编译步骤的三个参数：\r\n",
    "\r\n",
    "- 损失函数（loss function）：衡量在训练数据上的性能，即网络如何朝着正确的方向前进。\r\n",
    "- 优化器（optimizer）：基于训练数据和损失函数来更新网络的机制。\r\n",
    "- 在训练和测试过程中需要监控的指标：本例只关心精度，即正确分类的图像所占的比例。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "network.compile(optimizer='rmsprop',\r\n",
    "                loss='categorical_crossentropy',\r\n",
    "                metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "在训练之前，我们需要将数据变换为网络要求的形状，并缩放到所有值在 [0,1] 区间。比如，之前训练图像保存在 uint8 类型的数组种，其形状为 (60000, 28, 28)，取值区间为 [0, 255]。我们需要将其变换为 float32 数组，形状为 (60000, 28*28)，取值范围 0~1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\r\n",
    "train_images = train_images.astype('float32') / 255\r\n",
    "\r\n",
    "test_images = test_images.reshape((10000, 28 * 28))\r\n",
    "test_images = test_images.astype('float32') / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来对标签进行分类编码。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "train_labels = to_categorical(train_labels)\r\n",
    "test_labels = to_categorical(test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "准备开始训练网络，在 keras 中这一步是通过调用网络的 `fit` 方法来完成的"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2561 - accuracy: 0.9262\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1045 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0686 - accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0500 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9886\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16461af8820>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面显示两个数字：\r\n",
    "\r\n",
    "- 训练数据上的损失（loss）；\r\n",
    "- 网络在训练数据上的精度（accuracy）；\r\n",
    "\r\n",
    "上面很快就在训练数据上达到了 98.86%的精度。下面我们检查模型在测试集上的性能"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 0s 651us/step - loss: 0.0739 - accuracy: 0.9783\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试精度为97.83 %，比训练精度低。训练精度和测试精度之间的这种差距就是**过拟合**（overfit）。过拟合是指机器学习模型在新数据上的性能比在训练数据上要差。"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "e404b59586357c814bc0d3940e75d6763c00a48753b225b81f7716971b8e1741"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}