{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    \"\"\"\n",
    "    随机生成固定长度的序列样本。\n",
    "    序列由固定振幅，相位和频率随机的两个正弦波和随机噪音加和而成。\n",
    "    序列样本一般表示为 3D 数组 [batch size, time steps, dimensionality], 对单变量 dimensionality 为 1\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size 生成时间序列个数（样本数）\n",
    "    n_steps 序列长度\n",
    "    每个时间步一个值，即单变量序列\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))  # wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)  # noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建训练集、验证集和测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X_train 包含 7,000 条序列数据，其 shape 为 [7000, 500, 1]，\n",
    "X_valid 包含 2,000 条序列数据，从 7,000th 到 8,999th\n",
    "X_test 包含 1,000 条序列数据，从 9,000th 到 9,999th\n",
    "\n",
    "由于对每个序列只预测一个值，所以目标值为列向量，例如 y_train 的 shape 为 [7000, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基线指标\n",
    "\n",
    "在开始使用 RNN 之前，最好先定义一些基线指标，否则我们认为我们的模型很好，但实际上它比基本模型都差。例如，最简单的方法是预测每个序列的最后一个值。这就是所谓的朴素预测（naive forecasting），有时候要超越它十分困难。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_pred = X_valid[:, -1]  # 取 X 的最后一个值，作为预测的 y 值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.020602005"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "平均平方误差为 0.020。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "另一种方法是使用全连接网络。因为全连接需要一维数据，所以添加一个 `Flatten` 层。下面使用一个简单的线性回归模型，这样每个预测都将是时间序列中值的线性组合："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面我们以 MSE loss 和 Adam 优化器编译模型，训练 20 个 epochs，并在验证集上评估"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 2ms/step - loss: 0.1685\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1af35b575b0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.003472333773970604"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "损失值为 0.003，比 naive 方法好。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面是最简单的 RNN，只包含一层，该层只有一个 neuron。\n",
    "\n",
    "并且不需要指定输入序列长度，因为 RNN 可以处理任意长度序列。\n",
    "\n",
    "其初始状态 $h_{(init)}$ 设置为 0，和初始值 $x_{(0)}$ 传递给唯一的 neuron，该 neuron 计算加权和，应用 tanh 激活函数，获得输出 $y_0$。在 simple RNN，该输出还作为新的状态 $h_0$ 使用。该状态和 $x_{(1)}$ 再次传递给 neuron，反复执行，直到最后一步。最后一层输出 $y_{49}$ 。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"mse\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 0.2717\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.1429\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0684\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 12s 55ms/step - loss: 0.0470\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.0408\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.0367\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 0.0333\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0304\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 12s 53ms/step - loss: 0.0278\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 13s 58ms/step - loss: 0.0256\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0237\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0220\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0205\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 0.0192\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 0.0181\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.0170\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 0.0161\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0153\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 13s 61ms/step - loss: 0.0146\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0140\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1af361d92b0>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MSE 只到 0.014，比 naive 方法好点，但是没有简单的线性模型好。\n",
    "\n",
    "而且训练时间明显更长。\n",
    "\n",
    "不过应该要明白，线性模型对每个输入都有一个参数，加上 bias 项，共 51 个参数。\n",
    "\n",
    "而上面的 RNN 只有一个神经元，一个输入参数，一个 hidden 参数，一个 bias 想，只有 3 个参数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep RNNs\n",
    "\n",
    "下面使用深度循环神经网络，使用 `tf.keras` 实现 deep RNN 十分简单，叠加 RNN 即可。在这里我们使用 3 个 `SimpleRNN`，也可以使用其它 RNN 层，如 `LSTM` 或 `GRU`。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "除了最后一层，中间的循环层都要设置 `return_sequences=True`，否则循环层只输出 2D 数组，而不是 RNN 层所需的 3D 数组。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 46s 204ms/step - loss: 0.0385\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 45s 205ms/step - loss: 0.0063\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 46s 209ms/step - loss: 0.0051\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 45s 208ms/step - loss: 0.0046\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 45s 207ms/step - loss: 0.0040\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 45s 206ms/step - loss: 0.0038\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 44s 203ms/step - loss: 0.0036\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 45s 204ms/step - loss: 0.0036\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 45s 203ms/step - loss: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.0034\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 42s 192ms/step - loss: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 41s 189ms/step - loss: 0.0032\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 43s 197ms/step - loss: 0.0031\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 45s 207ms/step - loss: 0.0030\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 46s 208ms/step - loss: 0.0030\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 45s 206ms/step - loss: 0.0030\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 42s 193ms/step - loss: 0.0031\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 42s 194ms/step - loss: 0.0030\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 45s 207ms/step - loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1af42ab47f0>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面的深度 RNN，最后 MSE 达到 0.003，比线性模型好了。\n",
    "\n",
    "最后一层使用单变量的RNN并不合适。将其替换为 `Dense` 更好，速度会稍微快点，精确差不多，并且可以选择自己需要的激活函数。\n",
    "\n",
    "如果最后一个层使用 `Dense`，需要移除上一层的 `return_sequences=True` 设置。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}