{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # Keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f'Rank mismatch:\\n'\n",
    "                             f'    found {rank}: {shape.numpy()}\\n'\n",
    "                             f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent / 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "\n",
    "    return targ, inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
     ]
    }
   ],
   "source": [
    "targ, inp = load_data(path_to_file)\n",
    "print(inp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
     ]
    }
   ],
   "source": [
    "print(targ[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Despu\\xc3\\xa9s de haber encontrado su n\\xc3\\xbamero de tel\\xc3\\xa9fono, \\xc3\\xa9l la llam\\xc3\\xb3.'\n",
      " b'Tom sabe d\\xc3\\xb3nde est\\xc3\\xa1 escondido el dinero.'\n",
      " b'Mi esposa no se levanta antes que yo.' b'Veamos si podemos ayudarle.'\n",
      " b'Le estamos perdiendo.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'After he had found her phone number, he called her up.'\n",
      " b'Tom knows where the money is hidden.'\n",
      " b\"My wife doesn't get up before me.\" b\"Let's see if we can help you.\"\n",
      " b\"We're losing it.\"], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    print(example_input_batch[:5])\n",
    "    print()\n",
    "    print(example_target_batch[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ],
   "source": [
    "example_text = tf.constant(\"¿Todavía está en casa?\")\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, \"NFKD\").numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accented characters.\n",
    "    text = tf_text.normalize_utf8(text, \"NFKD\")\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, \"[^ a-z.?!,¿]\", \"\")\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, \"[.?!,¿]\", r\" \\0 \")\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join([\"[START]\", text, \"[END]\"], separator=\" \")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "source": [
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct, max_tokens=max_vocab_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_processor.adapt(inp)\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "input_text_processor.get_vocabulary()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size\n",
    ")\n",
    "\n",
    "output_text_processor.adapt(targ)\n",
    "output_text_processor.get_vocabulary()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
       "array([[   2,  180,    6,  141, 1001,   25,  463,    6,  283,   19],\n",
       "       [   2,   10,  117,   71,   20, 2777,    7,   93,    4,    3],\n",
       "       [   2,   24,  437,    9,   17, 1516,  130,    5,   39,    4]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tokens = input_text_processor(example_input_batch)\n",
    "example_tokens[:3, :10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] despues de haber encontrado su numero de telefono , el la llamo . [END]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "\" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens)\n",
    "plt.title(\"Token IDs\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title(\"Mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size, embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            # Return the sequence and state\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        )\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, (\"batch\", \"s\"))\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, (\"batch\", \"s\", \"embed_dim\"))\n",
    "\n",
    "        # 3. The GRU processes the embedding sequence.\n",
    "        #    output shape: (batch, s, enc_units)\n",
    "        #    state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, (\"batch\", \"s\", \"enc_units\"))\n",
    "        shape_checker(state, (\"batch\", \"enc_units\"))\n",
    "\n",
    "        # 4. Returns the new sequence and its state.\n",
    "        return output, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 15)\n",
      "Encoder output, shape (batch, s, units): (64, 15, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Convert the input text to tokens.\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "\n",
    "# Encode the input sequence.\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(), embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "\n",
    "print(f\"Input batch, shape (batch): {example_input_batch.shape}\")\n",
    "print(f\"Input batch tokens, shape (batch, s): {example_tokens.shape}\")\n",
    "print(f\"Encoder output, shape (batch, s, units): {example_enc_output.shape}\")\n",
    "print(f\"Encoder state, shape (batch, units): {example_enc_state.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b5474876513231b9b036d9cf4a862f0b962ae62bccefd38c62590f202aeee29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
