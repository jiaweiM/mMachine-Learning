# 权重的初始化

- [权重的初始化](#权重的初始化)
  - [简介](#简介)

2021-07-05, 17:07
***

## 简介

在神经网络的学习中，权重的初始值特别重要，设定什么样的权重初始值，经常关系到神经网络的学习能否成功。

权重衰减（weight decay）是抑制过拟合、提高泛化能力的技巧，简单来说，权值衰减是一种以减小权重参数的值为目的进行学习的方法。通过减小权重参数的值来抑制过拟合的发生。

如果想减小权重的值，一开始将初始值设为较小的值才是正途。但是 如果把权重初始值全部设为 0，将无法正确进行学习。如果将权重初始值设成一样的值，那么在误差反向传播中，所有的权重值都会进行相同的更新。因此，权重被更新为相同的值，神经网络拥有许多不同权重的意义就丧失了。为了防止“权重均一化”，必须随机生成初始值。

推荐初始值：

- 当激活函数使用 ReLU 时，权重初始值使用 He 初始值；
- 当激活函数为 sigmoid 或 tanh 等 S 型曲线函数时，初始值使用 Xavier 初始值。

这是目前的最佳实践。
