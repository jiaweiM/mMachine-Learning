{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678').\n",
    "# Maximum length of int is DIGITS\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 16s 8ms/step - loss: 1.7603 - accuracy: 0.3551 - val_loss: 1.5724 - val_accuracy: 0.4044\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "Q 2+227   T 229  ☒ 223 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 42+377  T 419  ☒ 481 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 481+326 T 807  ☒ 111 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 84+52   T 136  ☒ 550 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 729+3   T 732  ☒ 980 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 1+154   T 155  ☒ 120 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 449+32  T 481  ☒ 453 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 31+0    T 31   ☒ 11  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 77+0    T 77   ☒ 11  \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 774+91  T 865  ☒ 901 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3237 - accuracy: 0.5062 - val_loss: 1.1463 - val_accuracy: 0.5610\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 941+308 T 1249 ☒ 1211\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 922+877 T 1799 ☒ 1621\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 630+272 T 902  ☒ 892 \n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Q 956+136 T 1092 ☒ 1011\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 29+975  T 1004 ☒ 901 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 70+752  T 822  ☒ 715 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 112+461 T 573  ☒ 655 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 73+526  T 599  ☒ 699 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 336+37  T 373  ☒ 375 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 761+85  T 846  ☒ 855 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9997 - accuracy: 0.6314 - val_loss: 0.9282 - val_accuracy: 0.6482\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 689+15  T 704  ☒ 700 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 90+880  T 970  ☒ 978 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 4+858   T 862  ☒ 850 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 66+702  T 768  ☒ 770 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 24+290  T 314  ☒ 306 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 22+96   T 118  ☒ 128 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 19+330  T 349  ☒ 340 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 6+854   T 860  ☒ 850 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 48+754  T 802  ☒ 790 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 48+650  T 698  ☒ 680 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8329 - accuracy: 0.6953 - val_loss: 0.7851 - val_accuracy: 0.7125\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 707+745 T 1452 ☒ 1455\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 50+92   T 142  ☒ 135 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 686+670 T 1356 ☒ 1252\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 988+1   T 989  ☒ 999 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 118+583 T 701  ☒ 795 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 276+3   T 279  ☒ 278 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 12+729  T 741  ☒ 735 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 935+31  T 966  ☒ 967 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 19+752  T 771  ☒ 779 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 687+67  T 754  ☒ 753 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7202 - accuracy: 0.7376 - val_loss: 0.6939 - val_accuracy: 0.7448\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 652+20  T 672  ☒ 675 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 11+700  T 711  ☒ 712 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 847+498 T 1345 ☑ 1345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 130+29  T 159  ☒ 169 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 385+52  T 437  ☒ 431 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 71+763  T 834  ☒ 831 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+313   T 318  ☑ 318 \n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Q 29+9    T 38   ☒ 29  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 86+873  T 959  ☒ 951 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 90+672  T 762  ☒ 761 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.6027 - accuracy: 0.7818 - val_loss: 0.4937 - val_accuracy: 0.8202\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 485+3   T 488  ☑ 488 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 48+372  T 420  ☒ 411 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 131+1   T 132  ☑ 132 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 0+627   T 627  ☑ 627 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 92+996  T 1088 ☒ 1081\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 814+766 T 1580 ☒ 1588\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 19+319  T 338  ☒ 336 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 649+53  T 702  ☒ 701 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 327+86  T 413  ☒ 412 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 969+608 T 1577 ☒ 1565\n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.3622 - accuracy: 0.8807 - val_loss: 0.2726 - val_accuracy: 0.9169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 864+686 T 1550 ☑ 1550\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 95+3    T 98   ☒ 99  \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 583+63  T 646  ☑ 646 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 657+79  T 736  ☒ 735 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 75+897  T 972  ☒ 973 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 771+7   T 778  ☑ 778 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 141+4   T 145  ☑ 145 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 42+840  T 882  ☒ 883 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 67+927  T 994  ☑ 994 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 987+750 T 1737 ☑ 1737\n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.2160 - accuracy: 0.9424 - val_loss: 0.1792 - val_accuracy: 0.9532\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 976+59  T 1035 ☑ 1035\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Q 4+410   T 414  ☑ 414 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 946+316 T 1262 ☑ 1262\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 30+112  T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 894+383 T 1277 ☒ 1287\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 390+158 T 548  ☑ 548 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 657+9   T 666  ☑ 666 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 526+87  T 613  ☑ 613 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 110+546 T 656  ☑ 656 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 924+4   T 928  ☑ 928 \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.1461 - accuracy: 0.9632 - val_loss: 0.1135 - val_accuracy: 0.9725\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 18+595  T 613  ☑ 613 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 114+53  T 167  ☑ 167 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 534+882 T 1416 ☑ 1416\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 68+144  T 212  ☑ 212 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 59+807  T 866  ☑ 866 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 40+278  T 318  ☑ 318 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 41+45   T 86   ☑ 86  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 388+41  T 429  ☑ 429 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 165+36  T 201  ☑ 201 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 36+10   T 46   ☒ 45  \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0945 - accuracy: 0.9788 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 686+670 T 1356 ☑ 1356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 638+197 T 835  ☑ 835 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 48+372  T 420  ☑ 420 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 478+967 T 1445 ☑ 1445\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 62+992  T 1054 ☑ 1054\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 279+53  T 332  ☑ 332 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 722+92  T 814  ☑ 814 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 10+53   T 63   ☑ 63  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 279+7   T 286  ☑ 286 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 130+29  T 159  ☑ 159 \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0721 - accuracy: 0.9830 - val_loss: 0.0823 - val_accuracy: 0.9768\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 292+70  T 362  ☑ 362 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 164+27  T 191  ☑ 191 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 4+672   T 676  ☑ 676 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 31+84   T 115  ☑ 115 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 50+90   T 140  ☒ 130 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 2+232   T 234  ☑ 234 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 129+1   T 130  ☑ 130 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 949+972 T 1921 ☑ 1921\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 350+17  T 367  ☑ 367 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 12+314  T 326  ☑ 326 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0610 - accuracy: 0.9849 - val_loss: 0.0562 - val_accuracy: 0.9847\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 62+101  T 163  ☑ 163 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 993+62  T 1055 ☑ 1055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 559+19  T 578  ☑ 578 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 42+320  T 362  ☑ 362 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 8+45    T 53   ☑ 53  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+111   T 116  ☑ 116 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 397+58  T 455  ☑ 455 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 32+11   T 43   ☑ 43  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 402+9   T 411  ☑ 411 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 148+640 T 788  ☑ 788 \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0545 - accuracy: 0.9851 - val_loss: 0.0335 - val_accuracy: 0.9929\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 168+749 T 917  ☑ 917 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 215+48  T 263  ☑ 263 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 0+761   T 761  ☑ 761 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 69+852  T 921  ☑ 921 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 30+403  T 433  ☑ 433 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 6+837   T 843  ☑ 843 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 195+196 T 391  ☑ 391 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 32+700  T 732  ☑ 732 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 75+338  T 413  ☑ 413 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 74+2    T 76   ☑ 76  \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.0400 - accuracy: 0.9899 - val_loss: 0.0358 - val_accuracy: 0.9904\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 397+412 T 809  ☒ 819 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 735+236 T 971  ☑ 971 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 348+4   T 352  ☑ 352 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 75+423  T 498  ☑ 498 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 75+70   T 145  ☑ 145 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 619+59  T 678  ☑ 678 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 864+424 T 1288 ☑ 1288\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 483+2   T 485  ☑ 485 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 805+129 T 934  ☑ 934 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 1+199   T 200  ☒ 201 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 0.0186 - val_accuracy: 0.9966\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 83+707  T 790  ☑ 790 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 54+637  T 691  ☑ 691 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 843+25  T 868  ☑ 868 \n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Q 962+8   T 970  ☑ 970 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 59+340  T 399  ☑ 399 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 68+262  T 330  ☑ 330 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 871+45  T 916  ☑ 916 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 64+680  T 744  ☑ 744 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 73+496  T 569  ☑ 569 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 115+189 T 304  ☑ 304 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 0.0203 - val_accuracy: 0.9958\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 624+90  T 714  ☑ 714 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 828+20  T 848  ☑ 848 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 33+883  T 916  ☑ 916 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 13+657  T 670  ☑ 670 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 49+146  T 195  ☑ 195 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 594+65  T 659  ☑ 659 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 43+8    T 51   ☑ 51  \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 8+666   T 674  ☑ 674 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 979+91  T 1070 ☑ 1070\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 764+217 T 981  ☑ 981 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.0297 - val_accuracy: 0.9941\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 922+621 T 1543 ☑ 1543\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 20+137  T 157  ☑ 157 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 562+964 T 1526 ☑ 1526\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 8+490   T 498  ☑ 498 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 118+401 T 519  ☑ 519 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 156+480 T 636  ☑ 636 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 233+71  T 304  ☑ 304 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 33+219  T 252  ☑ 252 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 144+98  T 242  ☑ 242 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 311+62  T 373  ☑ 373 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.0104 - val_accuracy: 0.9985\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 48+887  T 935  ☑ 935 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 399+883 T 1282 ☑ 1282\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 936+58  T 994  ☑ 994 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 58+181  T 239  ☑ 239 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 109+421 T 530  ☑ 530 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 484+563 T 1047 ☑ 1047\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 631+665 T 1296 ☑ 1296\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 556+56  T 612  ☑ 612 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 469+930 T 1399 ☑ 1399\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 67+927  T 994  ☑ 994 \n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 0.0172 - val_accuracy: 0.9958\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 83+467  T 550  ☑ 550 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 29+59   T 88   ☑ 88  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 560+967 T 1527 ☑ 1527\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 3+643   T 646  ☑ 646 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 18+860  T 878  ☑ 878 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 87+255  T 342  ☑ 342 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 84+589  T 673  ☑ 673 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 6+132   T 138  ☑ 138 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 105+36  T 141  ☑ 141 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 6+811   T 817  ☑ 817 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 6+653   T 659  ☑ 659 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 731+164 T 895  ☑ 895 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 968+249 T 1217 ☑ 1217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 512+526 T 1038 ☑ 1038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 15+151  T 166  ☑ 166 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 31+0    T 31   ☑ 31  \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 50+279  T 329  ☑ 329 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 491+60  T 551  ☑ 551 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 236+74  T 310  ☑ 310 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 645+8   T 653  ☑ 653 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.0138 - val_accuracy: 0.9966\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 7+580   T 587  ☑ 587 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 843+64  T 907  ☑ 907 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 25+77   T 102  ☑ 102 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 63+10   T 73   ☑ 73  \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 99+33   T 132  ☑ 132 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 11+839  T 850  ☑ 850 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 344+26  T 370  ☑ 370 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 98+117  T 215  ☑ 215 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 588+2   T 590  ☑ 590 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 4+410   T 414  ☑ 414 \n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0245 - accuracy: 0.9940 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 39+56   T 95   ☑ 95  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 461+6   T 467  ☑ 467 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 391+2   T 393  ☑ 393 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 9+154   T 163  ☑ 163 \n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Q 474+288 T 762  ☑ 762 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 726+898 T 1624 ☑ 1624\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Q 50+252  T 302  ☑ 302 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 513+89  T 602  ☑ 602 \n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Q 995+51  T 1046 ☑ 1046\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 86+873  T 959  ☑ 959 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0142 - val_accuracy: 0.9966\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 69+532  T 601  ☑ 601 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 401+55  T 456  ☑ 456 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 587+869 T 1456 ☑ 1456\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 47+26   T 73   ☑ 73  \n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Q 791+87  T 878  ☑ 878 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 50+92   T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 67+55   T 122  ☑ 122 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 8+791   T 799  ☑ 799 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 293+45  T 338  ☑ 338 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 641+84  T 725  ☑ 725 \n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.0249 - val_accuracy: 0.9927\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 893+15  T 908  ☑ 908 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 932+24  T 956  ☑ 956 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 9+985   T 994  ☑ 994 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 79+395  T 474  ☑ 474 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 94+16   T 110  ☑ 110 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 78+234  T 312  ☑ 312 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 128+73  T 201  ☑ 201 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 312+52  T 364  ☑ 364 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 565+5   T 570  ☑ 570 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 313+3   T 316  ☑ 316 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0447 - val_accuracy: 0.9865\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 118+768 T 886  ☑ 886 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 36+764  T 800  ☑ 800 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 406+514 T 920  ☒ 910 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 180+44  T 224  ☑ 224 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 77+857  T 934  ☑ 934 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 65+816  T 881  ☑ 881 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 246+75  T 321  ☑ 321 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 738+723 T 1461 ☑ 1461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 183+2   T 185  ☑ 185 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 928+13  T 941  ☑ 941 \n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0534 - val_accuracy: 0.9812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 39+551  T 590  ☑ 590 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 888+599 T 1487 ☑ 1487\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 356+7   T 363  ☑ 363 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 434+42  T 476  ☑ 476 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 573+4   T 577  ☑ 577 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 824+7   T 831  ☑ 831 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 796+30  T 826  ☑ 826 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 300+64  T 364  ☑ 364 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 79+645  T 724  ☑ 724 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 271+30  T 301  ☑ 301 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 337+5   T 342  ☑ 342 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 38+668  T 706  ☑ 706 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 724+11  T 735  ☑ 735 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 51+397  T 448  ☑ 448 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 37+836  T 873  ☑ 873 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 133+93  T 226  ☑ 226 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 521+672 T 1193 ☑ 1193\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 689+86  T 775  ☑ 775 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 74+82   T 156  ☑ 156 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 646+479 T 1125 ☑ 1125\n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 919+126 T 1045 ☑ 1045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 11+354  T 365  ☑ 365 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 918+885 T 1803 ☑ 1803\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 15+829  T 844  ☑ 844 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 66+779  T 845  ☑ 845 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 684+42  T 726  ☑ 726 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 42+343  T 385  ☑ 385 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 0+108   T 108  ☑ 108 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 291+85  T 376  ☑ 376 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 649+82  T 731  ☑ 731 \n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 251+763 T 1014 ☑ 1014\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+241   T 246  ☑ 246 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 779+6   T 785  ☑ 785 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 59+936  T 995  ☑ 995 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 545+3   T 548  ☑ 548 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 50+789  T 839  ☑ 839 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 4+70    T 74   ☑ 74  \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 538+59  T 597  ☑ 597 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 55+546  T 601  ☑ 601 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 971+9   T 980  ☑ 980 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}