# 模型评估

## 简介

评估是数据挖掘的关键步骤。从数据中推断结构的方法有很多，但要确定在特定问题上哪种方法最合适，需要系统的方法来评估不同模型的效果。模型评估并不简单。

我们可以看看不同方法在训练集上的表现，但是远没有在独立测试集上估计的指标准确。当有大量数据集，可以在一个大型训练集上建模，在另一个大型测试集上试用。但是，通常情况下**标记数据、高质量数据很少**。

基于有限数据预测模型性能是有个有趣的问题。有许多不同的技术，不过重复交叉验证可能是大多数有限数据情况下的首选方法。为了确保差异不是由偶尔因素引起，通常还需要进行统计检验。

## 1. 训练和测试

## 2. 预测性能

## 3. 交叉验证

## 4. 其它估计方法

## 5. 超参数选择

## 6. 对比数据挖掘方案

## 7. 预测概率

前面默认目标是最大化预测的成功率。如果预测值与实际值一致，则预测正确，否则不正确，没有中间态，这种方案又称为 0-1 损失函数：预测正确时 loss 为 0，预测错误时 loss 为 1。

不过大多数学习算法对每个预测输出一个概率。例如，以 99% 的概率预测为正确的结果可能比以 51% 的概率预测为正确的结果更重要；在只有两个类别的情况，51% 正确的结果不一定比 51% 错误的结果好多少。是否应该考虑概率取决于具体应用。

### 平方损失函数

对单个实例，有 $k$ 个可能的结果或类别，并且对给定实例，学习算法会输出一个概率向量 $p_1, p_2,\cdots,p_k$，对应每个类别的概率，加和为 1。实际结果也表示为向量 $a_1,a_2,\cdots,a_k$，真实类别对应的 $a_i=1$，其它为 0.

平方损失函数常用于评估概率预测结果：
$$
\sum_j(p_j-a_j)^2
$$
这是针对一个实例的平方损失值。由于 $a$ 只有一个值为 1，其它为 0，因此对错误分类为 $p_j^2$，对正确分类为 $(1-p_i)^2$，因此上式可以重写为：
$$
1-2p_i+\sum_jp_j^2
$$
其中，$i$ 为正确类别，当测试集包含多个实例，则损失函数为所有实例损失值的加和。

通过最小化平方损失函数，可以得到概率的最佳估计值，所以**平方损失函数常用于概率预测**。

### 信息损失函数

信息损失函数也常用于评估概率预测：
$$
-\log_2p_i
$$
其中，第 $i$ 个为正确的预测。这与逻辑回归优化的对数似然函数的负数相同。它表示表达概率分布 $p_1,p_2,\cdots,p_k$ 和真实类别 $i$ 所需的最小 bits 数。由于概率总是小于 1，所以对数为负数，前面加符号转为正数。例如，假设只有两个类别（head 和 tail），且概率相同，则传输 head 出现的概率需要 $-\log_21/2=1$ 个字节。

和平方损失函数一样，当概率分布与真实概率分布相同，信息损失函数值最小。

信息损失函数的一个问题是，如果实际发生的概率为 0，该函数值为无穷大。

### 概率损失函数的选择

上面两个评估概率预测的损失函数，应该选择哪一个？

平方损失函数不仅考虑实际发生事件的概率，也包括其它概率。例如，假设有 4 个类别，正确类别概率为 40%，余下三个类别共享余下 60% 概率。**二次损失函数**计算 $p_j^2$ 的加和，当 60% 在余下三个类别平均分配，损失值最小。信息损失函数则只考虑真实类别的概率。

如果为正确分类分配很小的概率，信息损失函数会得到很大的惩罚值，0 概率的的惩罚为无穷大。而平方损失函数相对温和，其值受限于：
$$
1+\sum_jp_j^2
$$
平方损失函数值不会超过 2.

信息损失函数的支持者指出，机器学习中绩效评估的一般理论最小描述长度原理（minimum description length principle, MDL）。他们认为，可以用信息 bits 来衡量需要学习结构的大小，如果用相同单位来衡量损失，两者结合更为强大。



## 8. 