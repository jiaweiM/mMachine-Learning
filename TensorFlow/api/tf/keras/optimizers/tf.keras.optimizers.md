# tf.keras.optimizers

- [tf.keras.optimizers](#tfkerasoptimizers)
  - [类](#类)
  - [函数](#函数)
  - [参考](#参考)

2022-01-01, 14:04
***

## 类

|类|说明|
|---|---|
|Adadelta|Optimizer that implements the Adadelta algorithm.|
|Adagrad|Optimizer that implements the Adagrad algorithm.|
|Adam|Optimizer that implements the Adam algorithm.|
|Adamax|Optimizer that implements the Adamax algorithm.|
|Ftrl|Optimizer that implements the FTRL algorithm.|
|Nadam|Optimizer that implements the NAdam algorithm.|
|Optimizer|Base for Keras optimizers.|
|RMSprop|Optimizer that implements the RMSprop algorithm.|
|SGD|Gradient descent (with momentum) optimizer.|

## 函数

|函数|说明|
|---|---|
|deserialize(...)|Inverse of the serialize function.|
|get(...)|Retrieves a Keras Optimizer instance.|
|serialize(...)|Serialize the optimizer configuration to JSON compatible python dict.|

## 参考

- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers
