# 相关性

2022-03-12, 15:15
***

## 定义

相关性（correlation）指两个定量变量之间的关系。数据可以用有序对 $(x,y)$ 表示，其中 x 是自变量（independent variable），y 是因变量（dependent variable）。

**例 1：**  一位经济学家想确定一个国家的国内生产总值（GDP）与二氧化碳排放量之间是否存在线性关系。数据如下：

| GDP（万亿美元），$x$ | $\text{CO}_2$ 排放量（百万吨），$y$ |
| -------------------- | ---------------------------- |
| 1.8                  | 604.4                        |
| 1.3                  | 434.2                        |
| 2.4                  | 544.0                        |
| 1.5                  | 370.4                        |
| 3.9                  | 742.3                        |
| 2.1                  | 340.5                        |
| 0.9                  | 232.0                        |
| 1.4                  | 262.3                        |
| 3.0                  | 441.9                        |
| 4.6                  | 1157.7                       |

散点图可用于查看两个变量之间是否存在线性关系（直线相关性），绘出散点图：

![[Pasted image 20230529165748.png|500]]


## 协方差

如果两个随机变量 X 和 Y 是相互独立的，则：

$$E\{[X-E(x)][Y-E(Y)]\}=0$$

这意味着，当 $E\{[X-E(x)][Y-E(Y)]\}\ne 0$ 时，X 与 Y 不相互独立，而是存在一定的关系。

$E\{[X-E(x)][Y-E(Y)]\}$ 称为随机变量 X 与 Y 的协方差。记为 $Cov(X,Y)$，即：

$$Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}$$

而 

$$\rho_{xy}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$

称为随机变量 X 与 Y 的相关系数，即皮尔逊相关系数。

## 相关系数

散点图是对相关性的定性解释，而相关系数两个变量之间线性关系的类型和强度定量指标。**样本相关系数** $r$ 的定义为：

$$\begin{aligned}
r 
  &=\frac{n\sum xy-(\sum x)(\sum y)}{\sqrt{n\sum x^2-(\sum x)^2}\sqrt{n\sum y^2-(\sum y)^2}}
\end{aligned}

$$

其中 $n$ 是数据对数。总体相关系数一般用希腊字母 $\rho$ (row) 表示。该相关系数的正式名称为皮尔逊相关系数（Pearson correlation coefficient, PCC）。

相关系数的范围为 [-1, 1]：

- 当 x 和 y 强烈正线性相关，r 接近 1；
- 当 x 和 y 强烈负线性相关，r 接近 -1；
- 当 x 和 y 完全线性正相关或完全线性负相关，r 为 1 或 -1；
- 当不存在线性相关，r 接近 0.

```ad-note
当 $r$ 接近 0，并不意味着 $x$ 和 $y$ 之间没有关系，只是没有线性关系。
```

下图展示不同相关程度的散点图：

![](2022-03-12-15-31-59.png)

要使用相关系数 $r$ 来推断总体，需要：

1. 成对的样本数据 $(x,y)$ 是随机的；
2. x 和 y 服从二元正态分布（bivariate normal distribution）

使用 Python 计算相关系数：

```python
from scipy.stats import pearsonr  
import numpy as np  
  
x = np.array([1.8, 1.3, 2.4, 1.5, 3.9, 2.1, 0.9, 1.4, 3, 4.6])  # GDP  
y = np.array([604.4, 434.2, 544, 370.4, 742.3, 340.5, 232, 262.3, 441.9, 1157.7, ])  # CO2  
  
r = pearsonr(x, y)  
print(r)  
```

## 总体相关系数检验

在获得样本相关系数 $r$ 后，你可能需要确定，是否有足够证据表明总体相关系数 $\rho$ 是显著的。换句话说，基于少量的样本数据，是否能对包含所有这些成对数据的总体做出推断？

使用样本数据对总体数据做出的推断总有出错的可能。当你认为相关性显著而实际不显著时的比例，称为**显著性水平**（level of significance）。显著性水平 $\alpha$ 一般设置为 0.01 或 0.05：

- $\alpha=0.05$ 表示当你根据样品做出总体相关系数显著的决策，有 5% 的概率你判断错了
- $\alpha=0.01$ 表示犯这类错的概率只有 1%

设置较低的显著性水平，可能会漏掉一些显著的相关性。

为了使相关系数显著，其绝对值要接近 1。要确定总体相关系数 $\rho$ 是否显著，可以参考末尾的临界值表。当 $|r|$ 大于临界值。则有足够的证据表明相关性显著。否则，没有足够证据表明这种相关性是显著的。例如，对 5 对数据 $n=5$，显著性水平设为 $\alpha=0.01$，需要对比 $|r|$ 是否大于临界值 0.959，如下所示：

![[Pasted image 20230529174723.png|500]]

```ad-tip
当确定线性相关性是显著的，就能继续寻找最能描述数据的直线方程。该直线称为回归线（regression line）。
```

## 总体相关系数的假设检验

可以用假设检验来确定样本相关系数 $r$ 是否提供了足够的证据来证明总体相关系数 $\rho$ 显著。

$\rho$ 的假设检验可以是单边检验和双边检验，对应的零假设（null hypothesis）和备择假设（alternative hypothesis）如下：

**左侧检验：** $\begin{cases}H_0: \rho \ge 0 \quad (无显著负相关) \\H_a: \rho < 0 \quad (显著负相关)\end{cases}$

**右侧检验：** $\begin{cases}H_0: \rho \le 0 \quad (无显著正相关) \\H_1: \rho > 0 \quad (显著正相关)\end{cases}$

**双边检验：** $\begin{cases} H_0: \rho =0 \quad (无显著相关) \\H_1: \rho \ne 0 \quad (显著相关)\end{cases}$

可以用 t-test 来测试两个变量之间的相关性是否显著。其中检验统计量（test statistic）为 $r$，标准化检验统计量为：

$$t=\frac{r}{\sigma_r}=\frac{r}{\sqrt{\frac{1-r^2}{n-2}}}$$
服从自由度为 $n-2$ 的 t-分布，其中 $n$ 是数据量。

相关系数 $\rho$ 的 t-test 流程：

1. 确定零假设和备择假设
2. 指定显著性水平 $\alpha$
3. 确定自由度 $n-2$
4. 

## 皮尔逊相关系数的临界值

当 $r$ 的绝对值大于表的值，表示相关性显著。

| n   | $\alpha=0.05$ | $\alpha=0.01$ |
| --- | ------------- | ------------- |
| 4   | 0.950         | 0.990         |
| 5   | 0.878         | 0.959         |
| 6   | 0.811         | 0.917         |
| 7   | 0.754         | 0.875         |
| 8   | 0.707         | 0.834         |
| 9   | 0.666         | 0.798         |
| 10  | 0.632         | 0.765         |
| 11  | 0.602         | 0.735         |
| 12  | 0.576         | 0.708         |
| 13  | 0.553         | 0.684         |
| 14  | 0.532         | 0.661         |
| 15  | 0.514         | 0.641         |
| 16  | 0.497         | 0.623         |
| 17  | 0.482         | 0.606         |
| 18  | 0.468         | 0.590         |
| 19  | 0.456         | 0.575         |
| 20  | 0.444         | 0.561         |
| 21  | 0.433         | 0.549         |
| 22  | 0.423         | 0.537         |
| 23  | 0.413         | 0.526         |
| 24  | 0.404         | 0.515         |
| 25  | 0.396         | 0.505         |
| 26  | 0.388         | 0.496         |
| 27  | 0.381         | 0.487         |
| 28  | 0.374         | 0.479         |
| 29  | 0.367         | 0.471         |
| 30  | 0.361         | 0.463         |
| 35  | 0.334         | 0.430         |
| 40  | 0.312         | 0.403         |
| 45  | 0.294         | 0.380         |
| 50  | 0.279         | 0.361         |
| 55  | 0.266         | 0.345         |
| 60  | 0.254         | 0.330         |
| 65  | 0.244         | 0.317         |
| 70  | 0.235         | 0.306         |
| 75  | 0.227         | 0.296         |
| 80  | 0.220         | 0.286         |
| 85  | 0.213         | 0.278         |
| 90  | 0.207         | 0.270         |
| 95  | 0.202         | 0.263         |
| 100 | 0.197         | 0.256         |

